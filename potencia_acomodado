import matplotlib
import matplotlib.pyplot as plt 
import tensorflow as tf
import numpy as np






def generar_codigo_matlab(nombre_archivo='grafico_datos'):
    
    # Crear el contenido del archivo .m
    contenido_m = f"""
    % 
    % Archivo de script para graficar en MATLAB

    % Cargar datos desde el archivo
    datos = load('datos_mat3.txt');

    % Separar datos_x y datos_y
    datos_x = datos(:, 1);
    datos_y = datos(:, 2);

    %Graficar
    %figure;
    %plot(datos_x);
    %figure;
    %plot(datos_y);
    figure;
    hold on;
    %plot(datos_x);
    plot(datos_y);%plot(-0.5*datos_y+0.011);


datos2 = load('datos_mat2.txt');
datos_x1 = datos2(:, 2);

datos3 = load('datos_mat.txt');
datos_x2 = datos3(:, 2);

% Concatenar los datos verticalmente
datos_concatenados = cat(1, datos_x1, datos_x2);

figure;
hold on;
%plot(datos_x1, 'r'); % Graficar datos_x1 en rojo
%plot(datos_x2, 'b'); % Graficar datos_x2 en azul
plot(datos_concatenados, 'g');  % Graficar la concatenación en verde

xlabel('Índice de Datos');
ylabel('Valor');
legend('datos_x1', 'datos_x2', 'Concatenados');
title('Comparación de Datos Concatenados');
grid on;


%COMPARACION
figure;
hold on;
plot(datos_concatenados, 'g');  % Graficar la concatenación en verde
plot(datos_y);%plot(-0.5*datos_y+0.011);




    """

    # Guardar el contenido en un archivo .m
    with open(f"{nombre_archivo}.m", "w", encoding="utf-8") as archivo_matlab:
        archivo_matlab.write(contenido_m)




datos_despues_coma = []

try:
    with open('datos.txt', 'r') as archivo:
        lineas = archivo.readlines()  # Lee todas las líneas del archivo y las almacena en una lista
        
        # Procesar cada línea para obtener los datos antes y después de la coma:
        for linea in lineas:
            partes = linea.split(',')  # Divide la línea en función de la coma
            if len(partes) == 2:  # Asegurarse de que haya dos partes (antes y después de la coma)
                dato_despues_de_coma = float(partes[1].strip())  # Obtiene la parte después de la coma y elimina espacios en blanco
                datos_despues_coma.append(dato_despues_de_coma)
                
except FileNotFoundError:
    print("El archivo no se encontró")
except IOError:
    print("Ocurrió un error al leer el archivo")

        
########################################
#LEVANTE DE DATOS FIN
#######################################

maximo_valor = max(datos_despues_coma)
print(maximo_valor)

numeros_despues_coma_normalizados = [valor / maximo_valor for valor in datos_despues_coma]
print(datos_despues_coma);
print("DESPUES DE NORMALIZAR");
print(numeros_despues_coma_normalizados);
todos_los_datos = numeros_despues_coma_normalizados
# Definir la proporción de datos que deseas en numeros_despues_coma_normalizados
proporcion_datos_test = 0.5  # Por ejemplo, 20%

# Calcular la cantidad de datos que se trasladarán a datos_test
cantidad_datos_test = int(len(numeros_despues_coma_normalizados) * proporcion_datos_test)

# Mover los datos a datos_test
datos_test = numeros_despues_coma_normalizados[:cantidad_datos_test]
numeros_despues_coma_normalizados = numeros_despues_coma_normalizados[cantidad_datos_test:]



############################################
# MODELO
##########################################

np.random.seed(0)
tf.random.set_seed(0)

datos = np.array(numeros_despues_coma_normalizados, dtype=float)
eje_x_mediciones = np.arange(0, len(numeros_despues_coma_normalizados))


# Definir el modelo secuencial
modelo = tf.keras.Sequential()

# Agregar la primera capa oculta
modelo.add(tf.keras.layers.Dense(units=2, input_shape=[1], activation='linear', kernel_initializer='he_normal'))
#128 y 64 antes
#relu linear tanh
modelo.add(tf.keras.layers.Dense(units=2, activation='linear'))
modelo.add(tf.keras.layers.Dense(units=1, activation='linear'))

# Resumen del modelo
modelo.summary()

modelo.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss='mean_absolute_error'
    #mean_absolute_error
    #mean_squared_error
)


# Convertir la lista a un array de NumPy
numeros_despues_coma_array = np.array(numeros_despues_coma_normalizados)
# Asegurarte de que el array tiene la forma correcta (por ejemplo, [número de ejemplos, número de características])
numeros_despues_coma_array = numeros_despues_coma_array.reshape(-1, 1)

cant_valores = np.arange(len(numeros_despues_coma_array))
modelo.fit(cant_valores,numeros_despues_coma_array, epochs=50, batch_size=32, validation_split=0.2)

##
# PREDICCIONES
##

# Evaluar el modelo en el conjunto de datos de prueba


resultado = modelo.evaluate(cant_valores,numeros_despues_coma_array)
# Imprimir la pérdida y otras métricas (si se definieron)
print("Pérdida en datos de prueba:", resultado)

# Realizar predicciones en los datos de prueba

predicciones = modelo.predict(numeros_despues_coma_array)
########################################################################
################################################
### ATENCIONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
##### cambiar la forma de "list" a lo que espera que es con el reshape
predicciones2 = modelo.predict(datos_test)
#print("primer valor")
#predicciones = predicciones * 2
#print(predicciones[0])

#print("multiplique todo por")
#print(maximo_valor)
#print("primer valor")
#predicciones = [valor * maximo_valor for valor in predicciones] #desnormalizo

#plt.plot(eje_x_mediciones, datos, label='Valores reales entrenados')
#plt.plot(eje_x_mediciones, predicciones, label='Predicciones')

#plt.xlabel("Índice de Datos")
#plt.ylabel("Valor")
#plt.legend()
#plt.title('Comparación de Predicciones en Datos de Prueba')
#plt.show()

# desnormalizacion
print("el maximo valor")
print(maximo_valor)

todos_los_datos = [valor * maximo_valor for valor in todos_los_datos]
predicciones = [valor * maximo_valor for valor in predicciones]
predicciones2 = [valor * maximo_valor for valor in predicciones2]

# Guardar los datos en un archivo
cant_datos = np.arange(len(predicciones))
np.savetxt('datos_mat.txt', np.column_stack((cant_datos, predicciones )))
indices = np.arange(len(datos_test))
# Crear un array de datos a testear con los índices y las predicciones

cant_datos = np.arange(len(predicciones2))
np.savetxt('datos_mat2.txt', np.column_stack((cant_datos, predicciones2 )))
cant_datos = np.arange(len(todos_los_datos))

np.savetxt('datos_mat3.txt', np.column_stack((cant_datos,todos_los_datos)))

generar_codigo_matlab('mat')





# Obtener los últimos 'n' datos de entrenamiento (en este caso, n = 50)
ultimos_datos_entrenamiento = np.array(numeros_despues_coma_normalizados[-50:])

# Inicializar un array para almacenar las predicciones
predicciones_siguientes_50 = []

# Realizar las predicciones para los 50 siguientes valores
for _ in range(50):
    prediccion = modelo.predict(ultimos_datos_entrenamiento.reshape(-1, 1))
    predicciones_siguientes_50.append(prediccion[0])
    ultimos_datos_entrenamiento = np.roll(ultimos_datos_entrenamiento, -1)
    ultimos_datos_entrenamiento[-1] = prediccion[0]

# Imprimir las predicciones
print(predicciones_siguientes_50)
predicciones_siguientes_50 = [valor * maximo_valor for valor in predicciones_siguientes_50]
print("DESPUES DE DESNORMALIZAR")
print("Predicciones para los siguientes 50 valores:", predicciones_siguientes_50)

print("el maximo valor")
print(maximo_valor)